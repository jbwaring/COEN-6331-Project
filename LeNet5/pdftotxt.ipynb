{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "from pdfminer.converter import XMLConverter, HTMLConverter, TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "import io\n",
    "\n",
    "def pdfparser(data):\n",
    "\n",
    "    fp = open(data, 'rb')\n",
    "    rsrcmgr = PDFResourceManager()\n",
    "    retstr = io.StringIO()\n",
    "    codec = 'utf-8'\n",
    "    laparams = LAParams()\n",
    "    device = TextConverter(rsrcmgr, retstr, laparams=laparams)\n",
    "    # Create a PDF interpreter object.\n",
    "    interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
    "    # Process each page contained in the document.\n",
    "\n",
    "    for page in PDFPage.get_pages(fp):\n",
    "        interpreter.process_page(page)\n",
    "        data =  retstr.getvalue()\n",
    "\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title of Project\n",
      "\n",
      "COEN 6331 Project – Submitted to Dr. Kash Khorasani as partial fulfilment of the requirements of COEN 6331, Winter 2023.\n",
      "\n",
      "Mohsen Asghari\n",
      "ID: 40257411\n",
      "\n",
      "Jean-Baptiste Waring\n",
      "\n",
      "ID: 40054925\n",
      "\n",
      "Abstract—Nowadays, Machine Learning approaches have re-\n",
      "ceived large amounts of attention. Not only in the software\n",
      "aspect,\n",
      "in the area of robotics and edge devices, there is a\n",
      "trend of research for light weight approaches. Among the current\n",
      "researches, Hyper-dimensional Computing (HDC) has been con-\n",
      "sidered as a lightweight alternative to the Neural Networks. This\n",
      "approach mathematically proved that it solves classification prob-\n",
      "lems using the advantage of Hyper-Dimensional Vectors (HV)\n",
      "working on high dimensions around 10000. The most problematic\n",
      "part of HDC is the Encoder definition which is responsible for\n",
      "generating quasi-orthogonal HVs representing inputs. In this\n",
      "project, for an object detection problem (image classification), we\n",
      "want to use a/some frozen pre-trained convolutional layer/layers\n",
      "considered as the Encoder of HDC. We will use a pre-trained\n",
      "Convolutional Neural Network (CNN) such as Lenet5 or Resnet-\n",
      "12; then, we cut the first filtering layers and use them as the\n",
      "HDC Encoder.\n",
      "\n",
      "Index Terms—TO BE ADDED\n",
      "\n",
      "I. INTRODUCTION\n",
      "\n",
      "–Classification problem\n",
      "– whats HDC\n",
      "In this work, we aim to implement and improve upon\n",
      "the approach presented in the paper [1] for encoding high-\n",
      "dimensional data in the context of a Hyperdimensional Com-\n",
      "puting (HDC) Classifier. The authors have successfully em-\n",
      "ployed a pre-trained Convolution Neural Network (CNN) as\n",
      "the encoder for an HDC classifier. Our goal is to further\n",
      "optimize this approach by enhancing the performance of a\n",
      "modified LeNet-5 encoder and refining the integration of the\n",
      "HDC classifier. The primary motivation behind using CNNs,\n",
      "specifically the LeNet-5 architecture, is their proven capability\n",
      "in handling spatial data and their effectiveness in extracting\n",
      "meaningful features from raw input.\n",
      "\n",
      "–main contributions\n",
      "\n",
      "II. DATASET\n",
      "[2]\n",
      "\n",
      "The MNIST dataset\n",
      "\n",
      "is a widely-used and well-\n",
      "established benchmark for evaluating the performance of ma-\n",
      "chine learning algorithms, particularly in the field of image\n",
      "classification. Using MNIST as a dataset for evaluating our\n",
      "modified LeNet-5 encoder [3] and HDC classifier offers sev-\n",
      "eral advantages:\n",
      "\n",
      "1) Standard Benchmark: The MNIST dataset has become\n",
      "a standard benchmark for evaluating image classification\n",
      "algorithms, providing a reliable and consistent basis for\n",
      "comparison with other methods. By using MNIST, our\n",
      "\n",
      "results can be directly compared with other state-of-the-\n",
      "art approaches and provide a clear understanding of our\n",
      "method’s performance.\n",
      "2) Simplicity: The MNIST dataset consists of grayscale\n",
      "images of handwritten digits with a fixed size of 28×28\n",
      "pixels. The simplicity of the dataset allows for faster\n",
      "training and evaluation of the proposed method, enabling\n",
      "us to focus on optimizing the architecture and hyperpa-\n",
      "rameters.\n",
      "\n",
      "3) Wide Applicability: Despite its simplicity, the MNIST\n",
      "dataset effectively represents a wide range of real-world\n",
      "image classification tasks, such as character recognition\n",
      "and object detection. By achieving good performance on\n",
      "MNIST, our method demonstrates its potential for gen-\n",
      "eralization to other more complex image classification\n",
      "problems.\n",
      "\n",
      "4) Availability and Preprocessing: The MNIST dataset is\n",
      "widely available and has been extensively preprocessed,\n",
      "which facilitates easy access and use. The dataset is\n",
      "already split into training and testing sets, allowing for a\n",
      "straightforward evaluation of our method’s performance.\n",
      "5) Compatibility with LeNet-5: The original LeNet-5\n",
      "architecture was designed specifically for recognizing\n",
      "handwritten digits, making it well-suited for the MNIST\n",
      "dataset. By using the MNIST dataset, we can directly\n",
      "apply the modified LeNet-5 architecture and focus on\n",
      "improving its performance for HDC classification.\n",
      "\n",
      "By choosing the MNIST dataset, we can efficiently evaluate\n",
      "the performance of our modified LeNet-5 encoder and HDC\n",
      "classifier while ensuring a fair comparison with other methods.\n",
      "The dataset’s simplicity and compatibility with the LeNet-\n",
      "5 architecture allow us to focus on optimizing our approach\n",
      "and demonstrating its potential applicability to more complex\n",
      "image classification tasks. Figure 1 displays the first digit of\n",
      "each class (0-9) from the MNIST dataset.\n",
      "III. CNN ENCODER\n",
      "\n",
      "In this work, we have implemented a modified LeNet-5\n",
      "architecture as an encoder for the HDC classifier. This section\n",
      "presents the details of the implemented Convolutional Neural\n",
      "Network (CNN) architecture in the form of a ConvNeuralNet\n",
      "class using the PyTorch library. Detailed code can be found\n",
      "in Appendix A. The general architecture of LeNet-5 is shown\n",
      "Figure 2.\n",
      "\n",
      "\ftheir effectiveness and suitability for the classification task at\n",
      "hand. These choices enable the model to learn more efficiently,\n",
      "ultimately resulting in improved performance on the MNIST\n",
      "dataset.\n",
      "B. Utilizing a Pre-trained CNN as the Encoder\n",
      "\n",
      "After successfully pre-training a Convolutional Neural Net-\n",
      "work (CNN) that exhibits high accuracy, we modify its forward\n",
      "function to obtain the output from the penultimate hidden\n",
      "layer. It is hypothesized that this output serves as an effective\n",
      "query vector, given its capability to discern features of the\n",
      "input classes. The architecture of this network is shown Figure\n",
      "3 Figure 4 demonstrates an example of the input-output\n",
      "relationship. Here, the input has dimensions of 32× 32, while\n",
      "the output is 1× 400. The output is shown as a 20× 20 image.\n",
      "\n",
      "IV. CNN-HDC\n",
      "\n",
      "V. RESULTS\n",
      "\n",
      "VI. CONCLUSION\n",
      "\n",
      "REFERENCES\n",
      "\n",
      "[1] M. Hersche, G. Karunaratne, G. Cherubini, L. Benini, A. Sebastian, and\n",
      "\n",
      "A. Rahimi, “Constrained few-shot class-incremental learning,” 2022.\n",
      "\n",
      "[2] Y. LeCun, C. Cortes,\n",
      "database,”\n",
      "\n",
      "J. Burges,\n",
      "Labs\n",
      "written\n",
      "http://yann.lecun.com/exdb/mnist, vol. 2, 2010.\n",
      "\n",
      "and C.\n",
      "\n",
      "digit\n",
      "\n",
      "ATT\n",
      "\n",
      "“Mnist\n",
      "\n",
      "hand-\n",
      "Available:\n",
      "\n",
      "[Online].\n",
      "\n",
      "[3] Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based learning\n",
      "applied to document recognition,” Proceedings of the IEEE, vol. 86,\n",
      "no. 11, pp. 2278–2324, 1998.\n",
      "\n",
      "Fig. 1. The first digit of each class (0-9) from the MNIST dataset.\n",
      "\n",
      "A. Training the CNN\n",
      "\n",
      "The training loop plays a critical role in the learning process,\n",
      "as it iteratively updates the model parameters to minimize\n",
      "the loss. In this study, we opted for the cross-entropy loss\n",
      "as the cost function and the Adam optimizer to update the\n",
      "model parameters. Below, we explain the rationale behind\n",
      "these choices:\n",
      "\n",
      "1) Cross-Entropy Loss: The cross-entropy loss is a widely\n",
      "used cost function for classification tasks, especially\n",
      "when dealing with multiple classes. It measures the\n",
      "difference between the predicted probability distribution\n",
      "and the true distribution of the target classes. The cross-\n",
      "entropy loss is well-suited for our task because it is\n",
      "sensitive to the differences between the predicted and\n",
      "true probabilities, allowing the model\n",
      "to learn more\n",
      "effectively from misclassified samples. Moreover, this\n",
      "loss function has desirable properties, such as being\n",
      "differentiable, which is essential for gradient-based op-\n",
      "timization methods. It is defined as:\n",
      "\n",
      "∑\n",
      "\n",
      "𝐻( 𝑝, 𝑞) = −\n",
      "\n",
      "𝑝𝑖 log(𝑞𝑖)\n",
      "\n",
      "𝑖\n",
      "\n",
      "(1)\n",
      "Where 𝐻( 𝑝, 𝑞) represents the cross-entropy loss be-\n",
      "tween the true probability distribution 𝑝 and the pre-\n",
      "dicted probability distribution 𝑞. The sum is taken over\n",
      "all classes 𝑖, where 𝑝𝑖 is the true probability for class 𝑖\n",
      "and 𝑞𝑖 is the predicted probability for class 𝑖.\n",
      "\n",
      "2) Adam Optimizer: The choice of the optimizer is crucial\n",
      "in determining how the model parameters are updated\n",
      "during the training process. We chose the Adam (Adap-\n",
      "tive Moment Estimation) optimizer for this task due\n",
      "to its advantages over other optimization algorithms,\n",
      "such as stochastic gradient descent (SGD). Adam is an\n",
      "adaptive learning rate optimizer that computes individual\n",
      "learning rates for each parameter, which can help speed\n",
      "up convergence and improve model performance. Addi-\n",
      "tionally, Adam is computationally efficient and requires\n",
      "minimal memory, making it well-suited for large-scale\n",
      "problems and deep learning models like our modified\n",
      "LeNet-5.\n",
      "\n",
      "In summary, the choice of the cross-entropy loss function\n",
      "and the Adam optimizer in the training loop is motivated by\n",
      "\n",
      "Digit 0Digit 1Digit 2Digit 3Digit 4Digit 5Digit 6Digit 7Digit 8Digit 9\fFig. 2. Architecture of the LeNet5 CNN\n",
      "\n",
      " (1, 10)AddmmBackward0AccumulateGradfc2.bias (10)ReluBackward0AddmmBackward0AccumulateGradfc1.bias (84)ReluBackward0AddmmBackward0AccumulateGradfc.bias (120)ReshapeAliasBackward0MaxPool2DWithIndicesBackward0ReluBackward0NativeBatchNormBackward0ConvolutionBackward0MaxPool2DWithIndicesBackward0ReluBackward0NativeBatchNormBackward0ConvolutionBackward0AccumulateGradlayer1.0.weight (6, 1, 5, 5)AccumulateGradlayer1.0.bias (6)AccumulateGradlayer1.1.weight (6)AccumulateGradlayer1.1.bias (6)AccumulateGradlayer2.0.weight (16, 6, 5, 5)AccumulateGradlayer2.0.bias (16)AccumulateGradlayer2.1.weight (16)AccumulateGradlayer2.1.bias (16)TBackward0AccumulateGradfc.weight (120, 400)TBackward0AccumulateGradfc1.weight (84, 120)TBackward0AccumulateGradfc2.weight (10, 84)\fFig. 3. Architecture of the LeNet5 CNN used as an HDC Encoder.\n",
      "\n",
      "Fig. 4. Sample output from the CNN Encoder for an input of class ”2”.\n",
      "\n",
      " (1, 400)ReshapeAliasBackward0MaxPool2DWithIndicesBackward0 (1, 16, 5, 5)ReluBackward0NativeBatchNormBackward0ConvolutionBackward0MaxPool2DWithIndicesBackward0ReluBackward0NativeBatchNormBackward0ConvolutionBackward0AccumulateGradlayer1.0.weight (6, 1, 5, 5)AccumulateGradlayer1.0.bias (6)AccumulateGradlayer1.1.weight (6)AccumulateGradlayer1.1.bias (6)AccumulateGradlayer2.0.weight (16, 6, 5, 5)AccumulateGradlayer2.0.bias (16)AccumulateGradlayer2.1.weight (16)AccumulateGradlayer2.1.bias (16)\fAPPENDIX A\n",
      "\n",
      "CNN ENCODER IMPLEMENTATION\n",
      "\n",
      "The CustomLenet5 class is defined as follows:\n",
      "1) Initialization: The class constructor takes three arguments: num_classes, path, and use_big_hidden_layer. The\n",
      "num_classes parameter specifies the number of output classes for the final linear layer. The path parameter, if provided,\n",
      "loads a pre-trained model from the specified path. The use_big_hidden_layer parameter, if set to True, modifies the\n",
      "fully connected layer size to accommodate a larger hidden layer.\n",
      "\n",
      "2) Layers: The architecture consists of two sequential convolutional layers (layer1 and layer2), followed by fully connected\n",
      "layers (fc, fc1, and fc2). Each convolutional layer is followed by Batch Normalization, a ReLU activation function, and\n",
      "a max-pooling layer. The fully connected layers also include ReLU activation functions.\n",
      "\n",
      "3) HDC Mode: The HDCMode attribute is used to control whether the HDC classifier is enabled or disabled. The\n",
      "\n",
      "enableHDC() and disableHDC() methods are provided to set this attribute.\n",
      "\n",
      "4) Forward Pass: The forward() method defines the forward pass of the network. If the HDC mode is enabled, the\n",
      "method returns the output of the last fully connected layer, excluding the final output layer. Otherwise, it returns the\n",
      "output of the final layer.\n",
      "\n",
      "5) Forward Pass without Last Layer: The forwardWithoutLastLayer() method returns the output of the last fully\n",
      "\n",
      "connected layer, excluding the final output layer, regardless of the HDC mode.\n",
      "\n",
      "6) Save and Load: The save() and load() methods are provided for saving and loading the model’s state dictionary\n",
      "\n",
      "to/from a specified file path.\n",
      "\n",
      "The implemented modified LeNet-5 architecture serves as the encoder for our HDC classifier. By utilizing this encoder, we\n",
      "can efficiently extract robust and informative features from the input data, thereby improving the performance of the HDC\n",
      "classifier. The HDC mode enables us to selectively return the output from the last fully connected layer, which is particularly\n",
      "useful when integrating with the HDC classifier.\n",
      "import torch\n",
      "import torch.nn as nn\n",
      "\n",
      "class CustomLenet5(nn.Module):\n",
      "\n",
      "def __init__(self, num_classes, path=None, use_big_hidden_layer=False):\n",
      "\n",
      "super(CustomLenet5, self).__init__()\n",
      "self.USE_BIG_HIDDEN_LAYER = use_big_hidden_layer\n",
      "self.layer1 = nn.Sequential(\n",
      "\n",
      "nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
      "nn.BatchNorm2d(6),\n",
      "nn.ReLU(),\n",
      "nn.MaxPool2d(kernel_size=2, stride=2))\n",
      "\n",
      "self.layer2 = nn.Sequential(\n",
      "\n",
      "nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
      "nn.BatchNorm2d(16),\n",
      "nn.ReLU(),\n",
      "nn.MaxPool2d(kernel_size=2, stride=2))\n",
      "\n",
      "if (self.USE_BIG_HIDDEN_LAYER):\n",
      "\n",
      "self.fc = nn.Linear(400, 2048)\n",
      "self.relu = nn.ReLU()\n",
      "self.fc1 = nn.Linear(2048, 84)\n",
      "\n",
      "else:\n",
      "\n",
      "self.fc = nn.Linear(400, 120)\n",
      "self.relu = nn.ReLU()\n",
      "self.fc1 = nn.Linear(120, 84)\n",
      "\n",
      "self.relu1 = nn.ReLU()\n",
      "self.fc2 = nn.Linear(84, num_classes)\n",
      "if (path):\n",
      "\n",
      "try:\n",
      "\n",
      "except:\n",
      "\n",
      "self.load(path)\n",
      "\n",
      "1\n",
      "\n",
      "2\n",
      "\n",
      "3\n",
      "\n",
      "4\n",
      "\n",
      "5\n",
      "\n",
      "6\n",
      "\n",
      "7\n",
      "\n",
      "8\n",
      "\n",
      "9\n",
      "\n",
      "10\n",
      "\n",
      "11\n",
      "\n",
      "12\n",
      "\n",
      "13\n",
      "\n",
      "14\n",
      "\n",
      "15\n",
      "\n",
      "16\n",
      "\n",
      "17\n",
      "\n",
      "18\n",
      "\n",
      "19\n",
      "\n",
      "20\n",
      "\n",
      "21\n",
      "\n",
      "22\n",
      "\n",
      "23\n",
      "\n",
      "24\n",
      "\n",
      "25\n",
      "\n",
      "26\n",
      "\n",
      "27\n",
      "\n",
      "28\n",
      "\n",
      "29\n",
      "\n",
      "30\n",
      "\n",
      "31\n",
      "\n",
      "32\n",
      "\n",
      "\fprint(\"Error loading model from path\")\n",
      "\n",
      "self.HDCMode = False\n",
      "\n",
      "def enableHDC(self):\n",
      "\n",
      "self.HDCMode = True\n",
      "\n",
      "def disableHDC(self):\n",
      "\n",
      "self.HDCMode = False\n",
      "\n",
      "def forward(self, x):\n",
      "\n",
      "if (self.HDCMode is True):\n",
      "\n",
      "return self.forwardWithoutLastLayer(x)\n",
      "\n",
      "out = self.layer1(x)\n",
      "out = self.layer2(out)\n",
      "out = out.reshape(out.size(0), -1)\n",
      "out = self.fc(out)\n",
      "out = self.relu(out)\n",
      "out = self.fc1(out)\n",
      "out = self.relu1(out)\n",
      "out = self.fc2(out)\n",
      "return out\n",
      "\n",
      "def forwardWithoutLastLayer(self, x):\n",
      "\n",
      "out = self.layer1(x)\n",
      "out = self.layer2(out)\n",
      "if (self.USE_BIG_HIDDEN_LAYER):\n",
      "\n",
      "out = out.reshape(out.size(0), -1)\n",
      "out = self.fc(out)\n",
      "out = torch.sign(out)\n",
      "out = (out + 1) / 2\n",
      "\n",
      "# map -1 to 0 and 1 to 1\n",
      "\n",
      "out = out.reshape(out.size(0), -1)\n",
      "return out\n",
      "\n",
      "def save(self, path):\n",
      "\n",
      "torch.save(self.state_dict(), path)\n",
      "\n",
      "def load(self, path):\n",
      "\n",
      "self.load_state_dict(torch.load(path))\n",
      "\n",
      "33\n",
      "\n",
      "34\n",
      "\n",
      "35\n",
      "\n",
      "36\n",
      "\n",
      "37\n",
      "\n",
      "38\n",
      "\n",
      "39\n",
      "\n",
      "40\n",
      "\n",
      "41\n",
      "\n",
      "42\n",
      "\n",
      "43\n",
      "\n",
      "44\n",
      "\n",
      "45\n",
      "\n",
      "46\n",
      "\n",
      "47\n",
      "\n",
      "48\n",
      "\n",
      "49\n",
      "\n",
      "50\n",
      "\n",
      "51\n",
      "\n",
      "52\n",
      "\n",
      "53\n",
      "\n",
      "54\n",
      "\n",
      "55\n",
      "\n",
      "56\n",
      "\n",
      "57\n",
      "\n",
      "58\n",
      "\n",
      "59\n",
      "\n",
      "60\n",
      "\n",
      "61\n",
      "\n",
      "62\n",
      "\n",
      "63\n",
      "\n",
      "64\n",
      "\n",
      "65\n",
      "\n",
      "66\n",
      "\n",
      "67\n",
      "\n",
      "68\n",
      "\n",
      "69\n",
      "\n",
      "70\n",
      "\n",
      "71\n",
      "\n",
      "72\n",
      "\n",
      "\fORIGINALITY STATEMENT\n",
      "\n",
      "This form sets out the requirements for originality for work submitted by students in the Faculty of Engineering and\n",
      "Computer Science. Submissions such as assignments, lab reports, project reports, computer programs and take-home exams\n",
      "must conform to the requirements stated on this form and to the Academic Code of Conduct. The course outline may stipulate\n",
      "additional requirements for the course.\n",
      "\n",
      "1) Your submissions must be your own original work. Group submissions must be the original work of the students in the\n",
      "\n",
      "group.\n",
      "\n",
      "2) Direct quotations must not exceed 5% of the content of a report, must be enclosed in quotation marks, and must be\n",
      "attributed to the source by a numerical reference citation1. Note that engineering reports rarely contain direct quotations.\n",
      "\n",
      "3) Material paraphrased or taken from a source must be attributed to the source by a numerical reference citation.\n",
      "4) Text that is inserted from a web site must be enclosed in quotation marks and attributed to the web site by numerical\n",
      "\n",
      "5) Drawings, diagrams, photos, maps or other visual material taken from a source must be attributed to that source by a\n",
      "\n",
      "reference citation.\n",
      "\n",
      "numerical reference citation.\n",
      "\n",
      "6) No part of any assignment, lab report or project report submitted for this course can be submitted for any other course.\n",
      "7) In preparing your submissions, the work of other past or present students cannot be consulted, used, copied, paraphrased\n",
      "\n",
      "or relied upon in any manner whatsoever.\n",
      "\n",
      "8) Your submissions must consist entirely of your own or your group’s ideas, observations, calculations, information and\n",
      "\n",
      "conclusions, except for statements attributed to sources by numerical citation.\n",
      "\n",
      "9) Your submissions cannot be edited or revised by any other student.\n",
      "10) For lab reports, the data must be obtained from your own or your lab group’s experimental work.\n",
      "11) For software, the code must be composed by you or by the group submitting the work, except for code that is attributed\n",
      "\n",
      "to its sources by numerical reference.\n",
      "\n",
      "We hereby certify on our honour that this submission complies with the University’s Code of Conduct and Originality Policies.\n",
      "\n",
      "—————————————————————————————–\n",
      "\n",
      "Mohsen Asghari\n",
      "\n",
      "Jean-Baptiste Waring\n",
      "\n",
      "\f\n"
     ]
    }
   ],
   "source": [
    "pdfparser('COEN_6331_Project.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
