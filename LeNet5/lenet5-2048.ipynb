{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import getMNIST\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from lenet5.nn import ConvNeuralNet\n",
    "from utils import getTorchDevice\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "import torchhd.functional as functional\n",
    "from torch.nn.parameter import Parameter\n",
    "# Note: this example requires the torchmetrics library: https://torchmetrics.readthedocs.io\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "import struct\n",
    "import torch.nn.init as init\n",
    "\n",
    "import torchhd\n",
    "from torchhd.models import Centroid\n",
    "from torchhd import embeddings\n",
    "# Plot Font Config \n",
    "import torchhd\n",
    "import matplotlib.font_manager\n",
    "\n",
    "font_dirs = ['./IBM_Plex_Sans/']\n",
    "font_files = matplotlib.font_manager.findSystemFonts(fontpaths=font_dirs)\n",
    "\n",
    "for font_file in font_files:\n",
    "    matplotlib.font_manager.fontManager.addfont(font_file)\n",
    "plt.rcParams['font.family'] = 'IBM Plex Sans'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, test_ds, train_ld, test_ld = getMNIST(batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'),\n",
       " ConvNeuralNet(\n",
       "   (layer1): Sequential(\n",
       "     (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "     (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (2): ReLU()\n",
       "     (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (layer2): Sequential(\n",
       "     (0): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "     (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "     (2): ReLU()\n",
       "     (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (fc): Linear(in_features=400, out_features=120, bias=True)\n",
       "   (relu): ReLU()\n",
       "   (fc1): Linear(in_features=120, out_features=84, bias=True)\n",
       "   (relu1): ReLU()\n",
       "   (fc2): Linear(in_features=84, out_features=10, bias=True)\n",
       " ))"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = getTorchDevice()\n",
    "print(\"Using {} device\".format(device))\n",
    "# lenet = ConvNeuralNet(num_classes=10, use_big_hidden_layer=True).to(device)\n",
    "lenet = ConvNeuralNet(num_classes=10, use_big_hidden_layer=False).to(device)\n",
    "\n",
    "lenet.enableHDC()\n",
    "lenet.load(\"lenet5.pth\")\n",
    "device, lenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 60000/60000 [00:42<00:00, 1424.39it/s]\n",
      "Testing: 100%|██████████| 10000/10000 [00:08<00:00, 1219.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy of 92.480%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "# Note: this example requires the torchmetrics library: https://torchmetrics.readthedocs.io\n",
    "import torchmetrics\n",
    "from tqdm import tqdm\n",
    "import torchvision.transforms as transforms\n",
    "import torchhd\n",
    "from torchhd.models import Centroid\n",
    "from torchhd import embeddings\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using {} device\".format(device))\n",
    "lenet.enableHDC()\n",
    "DIMENSIONS = 400\n",
    "IMG_SIZE = 32\n",
    "NUM_LEVELS = 1000\n",
    "BATCH_SIZE = 1  # for GPUs with enough memory we can process multiple images at ones\n",
    "\n",
    "train_ds = MNIST(\"../data\", train=True, transform=transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                 transforms.ToTensor()]), download=True)\n",
    "train_ld = torch.utils.data.DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_ds = MNIST(\"../data\", train=False, transform=transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                 transforms.ToTensor()]), download=True)\n",
    "test_ld = torch.utils.data.DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, out_features, size, levels):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.flatten = torch.nn.Flatten()\n",
    "        self.position = embeddings.Random(size * size, out_features)\n",
    "        self.value = embeddings.Level(levels, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = lenet(x)\n",
    "        return torchhd.hard_quantize(x)\n",
    "\n",
    "\n",
    "encode = Encoder(DIMENSIONS, IMG_SIZE, NUM_LEVELS)\n",
    "encode = encode.to(device)\n",
    "\n",
    "num_classes = len(train_ds.classes)\n",
    "model = Centroid(DIMENSIONS, num_classes)\n",
    "model = model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for samples, labels in tqdm(train_ld, desc=\"Training\"):\n",
    "        samples = samples.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        samples_hv = encode(samples)\n",
    "        model.add(samples_hv, labels)\n",
    "\n",
    "accuracy = torchmetrics.Accuracy(\"multiclass\", num_classes=num_classes)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.normalize()\n",
    "\n",
    "    for samples, labels in tqdm(test_ld, desc=\"Testing\"):\n",
    "        samples = samples.to(device)\n",
    "\n",
    "        samples_hv = encode(samples)\n",
    "        outputs = model(samples_hv, dot=True)\n",
    "        accuracy.update(outputs.cpu(), labels)\n",
    "\n",
    "print(f\"Testing accuracy of {(accuracy.compute().item() * 100):.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testFullLENET5():\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        lenet.disableHDC()\n",
    "        for images, labels in tqdm(test_ld, desc=\"Testing\"):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = lenet(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the 10000 test images: {} %'.format(\n",
    "            100 * correct / total))\n",
    "def testHDC():\n",
    "    lenet.enableHDC()\n",
    "    with torch.no_grad():\n",
    "        model.normalize()\n",
    "        for samples, labels in tqdm(test_ld, desc=\"Testing\"):\n",
    "            samples = samples.to(device)\n",
    "            samples_hv = encode(samples)\n",
    "            outputs = model(samples_hv, dot=True)\n",
    "            accuracy.update(outputs.cpu(), labels)\n",
    "    print(f\"Testing accuracy of {(accuracy.compute().item() * 100):.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 10000/10000 [00:07<00:00, 1372.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 89.42 %\n",
      "Execution time (Full LENET5): None seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Execution time (Full LENET5):', testFullLENET5(), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 10000/10000 [00:08<00:00, 1216.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy of 92.480%\n",
      "Execution time (Full LENET5): None seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('Execution time (HDC):', testHDC(), 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
